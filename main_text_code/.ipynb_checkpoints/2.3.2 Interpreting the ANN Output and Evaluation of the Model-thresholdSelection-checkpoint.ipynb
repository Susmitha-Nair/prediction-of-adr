{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data - 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'prediction_of_ADR/ADR_dataset_for_training_subset_1.csv' does not exist: b'prediction_of_ADR/ADR_dataset_for_training_subset_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fd3d7c8a047f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Reading Actual Training Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrue_train1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction_of_ADR/ADR_dataset_for_training_subset_1.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrue_train2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction_of_ADR/ADR_dataset_for_training_subset_2.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrue_train3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction_of_ADR/ADR_dataset_for_training_subset_3.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrue_train4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction_of_ADR/ADR_dataset_for_training_subset_4.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'prediction_of_ADR/ADR_dataset_for_training_subset_1.csv' does not exist: b'prediction_of_ADR/ADR_dataset_for_training_subset_1.csv'"
     ]
    }
   ],
   "source": [
    "#Reading Actual Training Data\n",
    "true_train1 = pd.read_csv(\"../../Datasets/ADR_d\")\n",
    "true_train2 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_2.csv\")\n",
    "true_train3 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_3.csv\")\n",
    "true_train4 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_4.csv\")\n",
    "\n",
    "#Reading Predictions\n",
    "pred_train1 = np.load(\"pre1-ten-train.npy\")\n",
    "pred_train2 = np.load(\"pre2-ten-train.npy\")\n",
    "pred_train3 = np.load(\"pre3-ten-train.npy\")\n",
    "pred_train4 = np.load(\"pre4-ten-train.npy\")\n",
    "\n",
    "true_train1.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_train2.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_train3.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_train4.drop(\"Unnamed: 0\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Actual Testing Data\n",
    "true_test1 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_1.csv\")\n",
    "true_test2 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_2.csv\")\n",
    "true_test3 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_3.csv\")\n",
    "true_test4 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_4.csv\")\n",
    "\n",
    "#Reading Predictions\n",
    "pred_test1 = np.load(\"pre1-ten-test.npy\")\n",
    "pred_test2 = np.load(\"pre2-ten-test.npy\")\n",
    "pred_test3 = np.load(\"pre3-ten-test.npy\")\n",
    "pred_test4 = np.load(\"pre4-ten-test.npy\")\n",
    "\n",
    "true_test1.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_test2.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_test3.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_test4.drop(\"Unnamed: 0\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(243, 32549)\n",
      "(243, 32549)\n",
      "(243, 32549)\n",
      "(243, 32549)\n",
      "(243, 2000)\n",
      "(243, 2000)\n",
      "(243, 2000)\n",
      "(243, 2000)\n"
     ]
    }
   ],
   "source": [
    "true_train_labels1 = true_train1.values\n",
    "true_train_labels2 = true_train2.values\n",
    "true_train_labels3 = true_train3.values\n",
    "true_train_labels4 = true_train4.values\n",
    "\n",
    "true_train_labels1 = true_train_labels1.T\n",
    "true_train_labels2 = true_train_labels2.T\n",
    "true_train_labels3 = true_train_labels3.T\n",
    "true_train_labels4 = true_train_labels4.T\n",
    "\n",
    "print(true_train_labels1.shape)\n",
    "print(true_train_labels2.shape)\n",
    "print(true_train_labels3.shape)\n",
    "print(true_train_labels4.shape)\n",
    "\n",
    "\n",
    "true_test_labels1 = true_test1.values\n",
    "true_test_labels2 = true_test2.values\n",
    "true_test_labels3 = true_test3.values\n",
    "true_test_labels4 = true_test4.values\n",
    "\n",
    "true_test_labels1 = true_test_labels1.T\n",
    "true_test_labels2 = true_test_labels2.T\n",
    "true_test_labels3 = true_test_labels3.T\n",
    "true_test_labels4 = true_test_labels4.T\n",
    "\n",
    "print(true_test_labels1.shape)\n",
    "print(true_test_labels2.shape)\n",
    "print(true_test_labels3.shape)\n",
    "print(true_test_labels4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(243, 32549)\n",
      "(243, 32549)\n",
      "(243, 32549)\n",
      "(243, 32549)\n",
      "(243, 2000)\n",
      "(243, 2000)\n",
      "(243, 2000)\n",
      "(243, 2000)\n"
     ]
    }
   ],
   "source": [
    "pred_train1 = pred_train1.T\n",
    "pred_train2 = pred_train2.T\n",
    "pred_train3 = pred_train3.T\n",
    "pred_train4 = pred_train4.T\n",
    "\n",
    "print(pred_train1.shape)\n",
    "print(pred_train2.shape)\n",
    "print(pred_train3.shape)\n",
    "print(pred_train4.shape)\n",
    "\n",
    "\n",
    "pred_test1 = pred_test1.T\n",
    "pred_test2 = pred_test2.T\n",
    "pred_test3 = pred_test3.T\n",
    "pred_test4 = pred_test4.T\n",
    "\n",
    "print(pred_test1.shape)\n",
    "print(pred_test2.shape)\n",
    "print(pred_test3.shape)\n",
    "print(pred_test4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adrs = list(true_train1.columns)\n",
    "trueLabelsTrain = [true_train_labels1, true_train_labels2, true_train_labels3, true_train_labels4]\n",
    "trueLabelsTest = [true_test_labels1, true_test_labels2, true_test_labels3, true_test_labels4]\n",
    "predTrain = [pred_train1, pred_train2, pred_train3, pred_train4]\n",
    "predTest = [pred_test1, pred_test2, pred_test3, pred_test4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholds(pred):\n",
    "    thresholds = {}\n",
    "    index=0\n",
    "    for adr in adrs:\n",
    "        thresholds[adr] = np.linspace(min(pred[index]),max(pred[index]),100)\n",
    "        index+=1\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing best thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestThresholds(true_labels, pred, thresholds):\n",
    "    selectedThreshF1 = []\n",
    "\n",
    "    for adr in range(243):\n",
    "        maxThreshF1 = 0\n",
    "        maxScoreF1 = 0\n",
    "\n",
    "        for threshold in thresholds[adrs[adr]]:\n",
    "            temp = []\n",
    "            #Using training data only\n",
    "            for sample in range(len(pred[adr])):\n",
    "                if pred[adr][sample] > threshold:\n",
    "                    temp.append(1)\n",
    "                else:\n",
    "                    temp.append(0)\n",
    "\n",
    "            scoreF1 = f1_score(true_labels[adr], temp, average= \"macro\")\n",
    "\n",
    "            if scoreF1 > maxScoreF1:\n",
    "                maxThreshF1 = threshold\n",
    "                maxScoreF1 = scoreF1\n",
    "\n",
    "        selectedThreshF1.append(maxThreshF1)   \n",
    "    return selectedThreshF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selectedThresholds = []\n",
    "for i in range(4):\n",
    "    thresholds = getAllthresholds(predTrain[i])\n",
    "    selectedThresholds.append(getBestThresholds(trueLabelsTrain[i], predTrain[i], thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n",
      "243\n",
      "243\n",
      "243\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(len(selectedThresholds[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying thresholds to testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(4):\n",
    "    score = {'scoreF1': [], 'scoreAcc': [], 'scoreRoc': []}\n",
    "    pred_test = predTest[i]\n",
    "    thresholds = selectedThresholds[i]\n",
    "    truelabels = trueLabelsTest[i]\n",
    "    for adr in range(243):\n",
    "        temp = []\n",
    "        for sample in range(2000):\n",
    "            if pred_test[adr][sample] > thresholds[adr]:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        \n",
    "        score['scoreF1'].append(f1_score(truelabels[adr], temp, average= \"macro\"))\n",
    "        score['scoreAcc'].append(accuracy_score(truelabels[adr], temp))\n",
    "        score['scoreRoc'].append(roc_auc_score(truelabels[adr], temp, average= \"macro\"))\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame.from_dict(scores[0])\n",
    "df2 = pd.DataFrame.from_dict(scores[1])\n",
    "df3 = pd.DataFrame.from_dict(scores[2])\n",
    "df4 = pd.DataFrame.from_dict(scores[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = df1.columns)\n",
    "df[\"ADR\"] = adrs\n",
    "for i in range(243):\n",
    "    for j in range(3):\n",
    "        df.iloc[i,j] = (df1.iloc[i,j]+df2.iloc[i,j]+df3.iloc[i,j]+df4.iloc[i,j])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scoreF1</th>\n",
       "      <th>scoreAcc</th>\n",
       "      <th>scoreRoc</th>\n",
       "      <th>ADR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.703959</td>\n",
       "      <td>0.86475</td>\n",
       "      <td>0.702692</td>\n",
       "      <td>Drug.addiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.702245</td>\n",
       "      <td>0.825875</td>\n",
       "      <td>0.709496</td>\n",
       "      <td>bruxism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.692815</td>\n",
       "      <td>0.813875</td>\n",
       "      <td>0.698257</td>\n",
       "      <td>Mod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.691321</td>\n",
       "      <td>0.885625</td>\n",
       "      <td>0.699877</td>\n",
       "      <td>bursitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.69088</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.693449</td>\n",
       "      <td>fibromyalgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.575441</td>\n",
       "      <td>0.72125</td>\n",
       "      <td>0.579551</td>\n",
       "      <td>allergic.dermatitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.572399</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.57746</td>\n",
       "      <td>epistaxis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.571125</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>0.571133</td>\n",
       "      <td>edema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.568202</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.568957</td>\n",
       "      <td>Aspartate.Aminotransferase.Increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.561753</td>\n",
       "      <td>0.697625</td>\n",
       "      <td>0.56117</td>\n",
       "      <td>Feeling.unwell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      scoreF1  scoreAcc  scoreRoc                                  ADR\n",
       "28   0.703959   0.86475  0.702692                       Drug.addiction\n",
       "101  0.702245  0.825875  0.709496                              bruxism\n",
       "48   0.692815  0.813875  0.698257                                  Mod\n",
       "104  0.691321  0.885625  0.699877                             bursitis\n",
       "155   0.69088  0.859375  0.693449                         fibromyalgia\n",
       "..        ...       ...       ...                                  ...\n",
       "69   0.575441   0.72125  0.579551                  allergic.dermatitis\n",
       "149  0.572399     0.803   0.57746                            epistaxis\n",
       "144  0.571125    0.6615  0.571133                                edema\n",
       "11   0.568202     0.735  0.568957  Aspartate.Aminotransferase.Increase\n",
       "37   0.561753  0.697625   0.56117                       Feeling.unwell\n",
       "\n",
       "[243 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['scoreF1'], ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"average-ten-f1-based.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data - 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "seventy = pd.read_csv(\"ADR_combined_seventy.csv\")\n",
    "seventy.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Actual Training Data\n",
    "true_train1 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_1.csv\")\n",
    "true_train2 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_2.csv\")\n",
    "true_train3 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_3.csv\")\n",
    "true_train4 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_4.csv\")\n",
    "\n",
    "#Reading Predictions\n",
    "pred_train1 = np.load(\"pre1-s-train.npy\")\n",
    "pred_train2 = np.load(\"pre2-s-train.npy\")\n",
    "pred_train3 = np.load(\"pre3-s-train.npy\")\n",
    "pred_train4 = np.load(\"pre4-s-train.npy\")\n",
    "\n",
    "true_train1.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_train2.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_train3.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_train4.drop(\"Unnamed: 0\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Actual Testing Data\n",
    "true_test1 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_1.csv\")\n",
    "true_test2 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_2.csv\")\n",
    "true_test3 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_3.csv\")\n",
    "true_test4 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_4.csv\")\n",
    "\n",
    "#Reading Predictions\n",
    "pred_test1 = np.load(\"pre1-s.npy\")\n",
    "pred_test2 = np.load(\"pre2-s.npy\")\n",
    "pred_test3 = np.load(\"pre3-s.npy\")\n",
    "pred_test4 = np.load(\"pre4-s.npy\")\n",
    "\n",
    "true_test1.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_test2.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_test3.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_test4.drop(\"Unnamed: 0\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_train1 = true_train1[seventy.columns]\n",
    "true_train2 = true_train2[seventy.columns]\n",
    "true_train3 = true_train3[seventy.columns]\n",
    "true_train4 = true_train4[seventy.columns]\n",
    "\n",
    "true_test1 = true_test1[seventy.columns]\n",
    "true_test2 = true_test2[seventy.columns]\n",
    "true_test3 = true_test3[seventy.columns]\n",
    "true_test4 = true_test4[seventy.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 32549)\n",
      "(19, 32549)\n",
      "(19, 32549)\n",
      "(19, 32549)\n",
      "(19, 2000)\n",
      "(19, 2000)\n",
      "(19, 2000)\n",
      "(19, 2000)\n"
     ]
    }
   ],
   "source": [
    "true_train_labels1 = true_train1.values\n",
    "true_train_labels2 = true_train2.values\n",
    "true_train_labels3 = true_train3.values\n",
    "true_train_labels4 = true_train4.values\n",
    "\n",
    "true_train_labels1 = true_train_labels1.T\n",
    "true_train_labels2 = true_train_labels2.T\n",
    "true_train_labels3 = true_train_labels3.T\n",
    "true_train_labels4 = true_train_labels4.T\n",
    "\n",
    "print(true_train_labels1.shape)\n",
    "print(true_train_labels2.shape)\n",
    "print(true_train_labels3.shape)\n",
    "print(true_train_labels4.shape)\n",
    "\n",
    "\n",
    "true_test_labels1 = true_test1.values\n",
    "true_test_labels2 = true_test2.values\n",
    "true_test_labels3 = true_test3.values\n",
    "true_test_labels4 = true_test4.values\n",
    "\n",
    "true_test_labels1 = true_test_labels1.T\n",
    "true_test_labels2 = true_test_labels2.T\n",
    "true_test_labels3 = true_test_labels3.T\n",
    "true_test_labels4 = true_test_labels4.T\n",
    "\n",
    "print(true_test_labels1.shape)\n",
    "print(true_test_labels2.shape)\n",
    "print(true_test_labels3.shape)\n",
    "print(true_test_labels4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 32549)\n",
      "(19, 32549)\n",
      "(19, 32549)\n",
      "(19, 32549)\n",
      "(19, 2000)\n",
      "(19, 2000)\n",
      "(19, 2000)\n",
      "(19, 2000)\n"
     ]
    }
   ],
   "source": [
    "pred_train1 = pred_train1.T\n",
    "pred_train2 = pred_train2.T\n",
    "pred_train3 = pred_train3.T\n",
    "pred_train4 = pred_train4.T\n",
    "\n",
    "print(pred_train1.shape)\n",
    "print(pred_train2.shape)\n",
    "print(pred_train3.shape)\n",
    "print(pred_train4.shape)\n",
    "\n",
    "\n",
    "pred_test1 = pred_test1.T\n",
    "pred_test2 = pred_test2.T\n",
    "pred_test3 = pred_test3.T\n",
    "pred_test4 = pred_test4.T\n",
    "\n",
    "print(pred_test1.shape)\n",
    "print(pred_test2.shape)\n",
    "print(pred_test3.shape)\n",
    "print(pred_test4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adrs = list(true_train1.columns)\n",
    "trueLabelsTrain = [true_train_labels1, true_train_labels2, true_train_labels3, true_train_labels4]\n",
    "trueLabelsTest = [true_test_labels1, true_test_labels2, true_test_labels3, true_test_labels4]\n",
    "predTrain = [pred_train1, pred_train2, pred_train3, pred_train4]\n",
    "predTest = [pred_test1, pred_test2, pred_test3, pred_test4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllthresholds(pred):\n",
    "    thresholds = {}\n",
    "    index=0\n",
    "    for adr in adrs:\n",
    "        thresholds[adr] = np.linspace(min(pred[index]),max(pred[index]),100)\n",
    "        index+=1\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing best thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestThresholds(true_labels, pred, thresholds):\n",
    "    selectedThreshF1 = []\n",
    "\n",
    "    for adr in range(19):\n",
    "        maxThreshF1 = 0\n",
    "        maxScoreF1 = 0\n",
    "\n",
    "        for threshold in thresholds[adrs[adr]]:\n",
    "            temp = []\n",
    "            #Using training data only\n",
    "            for sample in range(len(pred[adr])):\n",
    "                if pred[adr][sample] > threshold:\n",
    "                    temp.append(1)\n",
    "                else:\n",
    "                    temp.append(0)\n",
    "\n",
    "            scoreF1 = f1_score(true_labels[adr], temp, average= \"macro\")\n",
    "\n",
    "            if scoreF1 > maxScoreF1:\n",
    "                maxThreshF1 = threshold\n",
    "                maxScoreF1 = scoreF1\n",
    "\n",
    "        selectedThreshF1.append(maxThreshF1)   \n",
    "    return selectedThreshF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedThresholds = []\n",
    "for i in range(4):\n",
    "    thresholds = getAllthresholds(predTrain[i])\n",
    "    selectedThresholds.append(getBestThresholds(trueLabelsTrain[i], predTrain[i], thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n",
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(len(selectedThresholds[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding thresholds to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(4):\n",
    "    score = {'scoreF1': [], 'scoreAcc': [], 'scoreRoc': []}\n",
    "    pred_test = predTest[i]\n",
    "    thresholds = selectedThresholds[i]\n",
    "    truelabels = trueLabelsTest[i]\n",
    "    for adr in range(19):\n",
    "        temp = []\n",
    "        for sample in range(2000):\n",
    "            if pred_test[adr][sample] > thresholds[adr]:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        \n",
    "        score['scoreF1'].append(f1_score(truelabels[adr], temp, average= \"macro\"))\n",
    "        score['scoreAcc'].append(accuracy_score(truelabels[adr], temp))\n",
    "        score['scoreRoc'].append(roc_auc_score(truelabels[adr], temp, average= \"macro\"))\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame.from_dict(scores[0])\n",
    "df2 = pd.DataFrame.from_dict(scores[1])\n",
    "df3 = pd.DataFrame.from_dict(scores[2])\n",
    "df4 = pd.DataFrame.from_dict(scores[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = df1.columns)\n",
    "df[\"ADR\"] = adrs\n",
    "for i in range(19):\n",
    "    for j in range(3):\n",
    "        df.iloc[i,j] = (df1.iloc[i,j]+df2.iloc[i,j]+df3.iloc[i,j]+df4.iloc[i,j])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scoreF1</th>\n",
       "      <th>scoreAcc</th>\n",
       "      <th>scoreRoc</th>\n",
       "      <th>ADR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.669365</td>\n",
       "      <td>0.722875</td>\n",
       "      <td>0.668807</td>\n",
       "      <td>Back.Ache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.659741</td>\n",
       "      <td>0.697125</td>\n",
       "      <td>0.660225</td>\n",
       "      <td>chest.pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.655948</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.655773</td>\n",
       "      <td>Hypoventilation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.654119</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.652946</td>\n",
       "      <td>Pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.644695</td>\n",
       "      <td>0.686125</td>\n",
       "      <td>0.644505</td>\n",
       "      <td>pleural.pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.64458</td>\n",
       "      <td>0.6925</td>\n",
       "      <td>0.642995</td>\n",
       "      <td>edema.extremities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.630717</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.629421</td>\n",
       "      <td>High.blood.pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.627529</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.626161</td>\n",
       "      <td>abdominal.pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.6173</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>0.616362</td>\n",
       "      <td>asthenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.614062</td>\n",
       "      <td>0.645625</td>\n",
       "      <td>0.614471</td>\n",
       "      <td>Fatigue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.613169</td>\n",
       "      <td>0.640875</td>\n",
       "      <td>0.61301</td>\n",
       "      <td>nausea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.612639</td>\n",
       "      <td>0.669125</td>\n",
       "      <td>0.612902</td>\n",
       "      <td>dizziness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.608854</td>\n",
       "      <td>0.626125</td>\n",
       "      <td>0.60961</td>\n",
       "      <td>anaemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.608703</td>\n",
       "      <td>0.646875</td>\n",
       "      <td>0.608577</td>\n",
       "      <td>neumonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.60371</td>\n",
       "      <td>0.643625</td>\n",
       "      <td>0.602954</td>\n",
       "      <td>diarrhea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.596375</td>\n",
       "      <td>0.612375</td>\n",
       "      <td>0.596554</td>\n",
       "      <td>arterial.pressure.NOS.decreased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.591322</td>\n",
       "      <td>0.614625</td>\n",
       "      <td>0.590632</td>\n",
       "      <td>Difficulty.breathing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.587397</td>\n",
       "      <td>0.636125</td>\n",
       "      <td>0.588486</td>\n",
       "      <td>emesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.583155</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.583697</td>\n",
       "      <td>body.temperature.increased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     scoreF1  scoreAcc  scoreRoc                              ADR\n",
       "0   0.669365  0.722875  0.668807                        Back.Ache\n",
       "11  0.659741  0.697125  0.660225                       chest.pain\n",
       "4   0.655948     0.689  0.655773                  Hypoventilation\n",
       "5   0.654119    0.6845  0.652946                             Pain\n",
       "18  0.644695  0.686125  0.644505                     pleural.pain\n",
       "14   0.64458    0.6925  0.642995                edema.extremities\n",
       "3   0.630717     0.692  0.629421              High.blood.pressure\n",
       "6   0.627529    0.6825  0.626161                   abdominal.pain\n",
       "9     0.6173    0.6565  0.616362                         asthenia\n",
       "2   0.614062  0.645625  0.614471                          Fatigue\n",
       "16  0.613169  0.640875   0.61301                           nausea\n",
       "13  0.612639  0.669125  0.612902                        dizziness\n",
       "7   0.608854  0.626125   0.60961                          anaemia\n",
       "17  0.608703  0.646875  0.608577                         neumonia\n",
       "12   0.60371  0.643625  0.602954                         diarrhea\n",
       "8   0.596375  0.612375  0.596554  arterial.pressure.NOS.decreased\n",
       "1   0.591322  0.614625  0.590632             Difficulty.breathing\n",
       "15  0.587397  0.636125  0.588486                           emesis\n",
       "10  0.583155     0.642  0.583697       body.temperature.increased"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['scoreF1'], ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"average-seventy-f1-based.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data - 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ninety = pd.read_csv(\"ADR_combined_ninety.csv\")\n",
    "ninety.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Actual Training Data\n",
    "true_train1 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_1.csv\")\n",
    "true_train2 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_2.csv\")\n",
    "true_train3 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_3.csv\")\n",
    "true_train4 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_4.csv\")\n",
    "\n",
    "#Reading Predictions\n",
    "pred_train1 = np.load(\"pre1-n-train.npy\")\n",
    "pred_train2 = np.load(\"pre2-n-train.npy\")\n",
    "pred_train3 = np.load(\"pre3-n-train.npy\")\n",
    "pred_train4 = np.load(\"pre4-n-train.npy\")\n",
    "\n",
    "true_train1.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_train2.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_train3.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_train4.drop(\"Unnamed: 0\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Actual Testing Data\n",
    "true_test1 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_1.csv\")\n",
    "true_test2 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_2.csv\")\n",
    "true_test3 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_3.csv\")\n",
    "true_test4 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_4.csv\")\n",
    "\n",
    "#Reading Predictions\n",
    "pred_test1 = np.load(\"pre1-n.npy\")\n",
    "pred_test2 = np.load(\"pre2-n.npy\")\n",
    "pred_test3 = np.load(\"pre3-n.npy\")\n",
    "pred_test4 = np.load(\"pre4-n.npy\")\n",
    "\n",
    "true_test1.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_test2.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_test3.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_test4.drop(\"Unnamed: 0\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_train1 = true_train1[ninety.columns]\n",
    "true_train2 = true_train2[ninety.columns]\n",
    "true_train3 = true_train3[ninety.columns]\n",
    "true_train4 = true_train4[ninety.columns]\n",
    "\n",
    "true_test1 = true_test1[ninety.columns]\n",
    "true_test2 = true_test2[ninety.columns]\n",
    "true_test3 = true_test3[ninety.columns]\n",
    "true_test4 = true_test4[ninety.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32549)\n",
      "(3, 32549)\n",
      "(3, 32549)\n",
      "(3, 32549)\n",
      "(3, 2000)\n",
      "(3, 2000)\n",
      "(3, 2000)\n",
      "(3, 2000)\n"
     ]
    }
   ],
   "source": [
    "true_train_labels1 = true_train1.values\n",
    "true_train_labels2 = true_train2.values\n",
    "true_train_labels3 = true_train3.values\n",
    "true_train_labels4 = true_train4.values\n",
    "\n",
    "true_train_labels1 = true_train_labels1.T\n",
    "true_train_labels2 = true_train_labels2.T\n",
    "true_train_labels3 = true_train_labels3.T\n",
    "true_train_labels4 = true_train_labels4.T\n",
    "\n",
    "print(true_train_labels1.shape)\n",
    "print(true_train_labels2.shape)\n",
    "print(true_train_labels3.shape)\n",
    "print(true_train_labels4.shape)\n",
    "\n",
    "\n",
    "true_test_labels1 = true_test1.values\n",
    "true_test_labels2 = true_test2.values\n",
    "true_test_labels3 = true_test3.values\n",
    "true_test_labels4 = true_test4.values\n",
    "\n",
    "true_test_labels1 = true_test_labels1.T\n",
    "true_test_labels2 = true_test_labels2.T\n",
    "true_test_labels3 = true_test_labels3.T\n",
    "true_test_labels4 = true_test_labels4.T\n",
    "\n",
    "print(true_test_labels1.shape)\n",
    "print(true_test_labels2.shape)\n",
    "print(true_test_labels3.shape)\n",
    "print(true_test_labels4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32549)\n",
      "(3, 32549)\n",
      "(3, 32549)\n",
      "(3, 32549)\n",
      "(3, 2000)\n",
      "(3, 2000)\n",
      "(3, 2000)\n",
      "(3, 2000)\n"
     ]
    }
   ],
   "source": [
    "pred_train1 = pred_train1.T\n",
    "pred_train2 = pred_train2.T\n",
    "pred_train3 = pred_train3.T\n",
    "pred_train4 = pred_train4.T\n",
    "\n",
    "print(pred_train1.shape)\n",
    "print(pred_train2.shape)\n",
    "print(pred_train3.shape)\n",
    "print(pred_train4.shape)\n",
    "\n",
    "\n",
    "pred_test1 = pred_test1.T\n",
    "pred_test2 = pred_test2.T\n",
    "pred_test3 = pred_test3.T\n",
    "pred_test4 = pred_test4.T\n",
    "\n",
    "print(pred_test1.shape)\n",
    "print(pred_test2.shape)\n",
    "print(pred_test3.shape)\n",
    "print(pred_test4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "adrs = list(true_train1.columns)\n",
    "trueLabelsTrain = [true_train_labels1, true_train_labels2, true_train_labels3, true_train_labels4]\n",
    "trueLabelsTest = [true_test_labels1, true_test_labels2, true_test_labels3, true_test_labels4]\n",
    "predTrain = [pred_train1, pred_train2, pred_train3, pred_train4]\n",
    "predTest = [pred_test1, pred_test2, pred_test3, pred_test4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllthresholds(pred):\n",
    "    thresholds = {}\n",
    "    index=0\n",
    "    for adr in adrs:\n",
    "        thresholds[adr] = np.linspace(min(pred[index]),max(pred[index]),100)\n",
    "        index+=1\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing best thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestThresholds(true_labels, pred, thresholds):\n",
    "    selectedThreshF1 = []\n",
    "\n",
    "    for adr in range(3):\n",
    "        maxThreshF1 = 0\n",
    "        maxScoreF1 = 0\n",
    "\n",
    "        for threshold in thresholds[adrs[adr]]:\n",
    "            temp = []\n",
    "            #Using training data only\n",
    "            for sample in range(len(pred[adr])):\n",
    "                if pred[adr][sample] > threshold:\n",
    "                    temp.append(1)\n",
    "                else:\n",
    "                    temp.append(0)\n",
    "\n",
    "            scoreF1 = f1_score(true_labels[adr], temp, average= \"macro\")\n",
    "\n",
    "            if scoreF1 > maxScoreF1:\n",
    "                maxThreshF1 = threshold\n",
    "                maxScoreF1 = scoreF1\n",
    "\n",
    "        selectedThreshF1.append(maxThreshF1)   \n",
    "    return selectedThreshF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedThresholds = []\n",
    "for i in range(4):\n",
    "    thresholds = getAllthresholds(predTrain[i])\n",
    "    selectedThresholds.append(getBestThresholds(trueLabelsTrain[i], predTrain[i], thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(len(selectedThresholds[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding thresholds to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(4):\n",
    "    score = {'scoreF1': [], 'scoreAcc': [], 'scoreRoc': []}\n",
    "    pred_test = predTest[i]\n",
    "    thresholds = selectedThresholds[i]\n",
    "    truelabels = trueLabelsTest[i]\n",
    "    for adr in range(3):\n",
    "        temp = []\n",
    "        for sample in range(2000):\n",
    "            if pred_test[adr][sample] > thresholds[adr]:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        \n",
    "        score['scoreF1'].append(f1_score(truelabels[adr], temp, average= \"macro\"))\n",
    "        score['scoreAcc'].append(accuracy_score(truelabels[adr], temp))\n",
    "        score['scoreRoc'].append(roc_auc_score(truelabels[adr], temp, average= \"macro\"))\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame.from_dict(scores[0])\n",
    "df2 = pd.DataFrame.from_dict(scores[1])\n",
    "df3 = pd.DataFrame.from_dict(scores[2])\n",
    "df4 = pd.DataFrame.from_dict(scores[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = df1.columns)\n",
    "df[\"ADR\"] = adrs\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        df.iloc[i,j] = (df1.iloc[i,j]+df2.iloc[i,j]+df3.iloc[i,j]+df4.iloc[i,j])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scoreF1</th>\n",
       "      <th>scoreAcc</th>\n",
       "      <th>scoreRoc</th>\n",
       "      <th>ADR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.622279</td>\n",
       "      <td>0.6305</td>\n",
       "      <td>0.622365</td>\n",
       "      <td>arterial.pressure.NOS.decreased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.608082</td>\n",
       "      <td>0.624125</td>\n",
       "      <td>0.609402</td>\n",
       "      <td>anaemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.599722</td>\n",
       "      <td>Difficulty.breathing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    scoreF1  scoreAcc  scoreRoc                              ADR\n",
       "2  0.622279    0.6305  0.622365  arterial.pressure.NOS.decreased\n",
       "1  0.608082  0.624125  0.609402                          anaemia\n",
       "0  0.599976     0.621  0.599722             Difficulty.breathing"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['scoreF1'], ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"average-ninety-f1-based.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data - 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty = pd.read_excel(\"thirty_percent.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Actual Training Data\n",
    "true_train1 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_1.csv\")\n",
    "true_train2 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_2.csv\")\n",
    "true_train3 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_3.csv\")\n",
    "true_train4 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_4.csv\")\n",
    "\n",
    "#Reading Predictions\n",
    "pred_train1 = np.load(\"pre1-t-train.npy\")\n",
    "pred_train2 = np.load(\"pre2-t-train.npy\")\n",
    "pred_train3 = np.load(\"pre3-t-train.npy\")\n",
    "pred_train4 = np.load(\"pre4-t-train.npy\")\n",
    "\n",
    "true_train1.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_train2.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_train3.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_train4.drop(\"Unnamed: 0\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Actual Testing Data\n",
    "true_test1 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_1.csv\")\n",
    "true_test2 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_2.csv\")\n",
    "true_test3 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_3.csv\")\n",
    "true_test4 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_4.csv\")\n",
    "\n",
    "#Reading Predictions\n",
    "pred_test1 = np.load(\"pre1-t.npy\")\n",
    "pred_test2 = np.load(\"pre2-t.npy\")\n",
    "pred_test3 = np.load(\"pre3-t.npy\")\n",
    "pred_test4 = np.load(\"pre4-t.npy\")\n",
    "\n",
    "true_test1.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_test2.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_test3.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_test4.drop(\"Unnamed: 0\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_train1 = true_train1[thirty['ADR']]\n",
    "true_train2 = true_train2[thirty['ADR']]\n",
    "true_train3 = true_train3[thirty['ADR']]\n",
    "true_train4 = true_train4[thirty['ADR']]\n",
    "\n",
    "true_test1 = true_test1[thirty['ADR']]\n",
    "true_test2 = true_test2[thirty['ADR']]\n",
    "true_test3 = true_test3[thirty['ADR']]\n",
    "true_test4 = true_test4[thirty['ADR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 32549)\n",
      "(165, 32549)\n",
      "(165, 32549)\n",
      "(165, 32549)\n",
      "(165, 2000)\n",
      "(165, 2000)\n",
      "(165, 2000)\n",
      "(165, 2000)\n"
     ]
    }
   ],
   "source": [
    "true_train_labels1 = true_train1.values\n",
    "true_train_labels2 = true_train2.values\n",
    "true_train_labels3 = true_train3.values\n",
    "true_train_labels4 = true_train4.values\n",
    "\n",
    "true_train_labels1 = true_train_labels1.T\n",
    "true_train_labels2 = true_train_labels2.T\n",
    "true_train_labels3 = true_train_labels3.T\n",
    "true_train_labels4 = true_train_labels4.T\n",
    "\n",
    "print(true_train_labels1.shape)\n",
    "print(true_train_labels2.shape)\n",
    "print(true_train_labels3.shape)\n",
    "print(true_train_labels4.shape)\n",
    "\n",
    "\n",
    "true_test_labels1 = true_test1.values\n",
    "true_test_labels2 = true_test2.values\n",
    "true_test_labels3 = true_test3.values\n",
    "true_test_labels4 = true_test4.values\n",
    "\n",
    "true_test_labels1 = true_test_labels1.T\n",
    "true_test_labels2 = true_test_labels2.T\n",
    "true_test_labels3 = true_test_labels3.T\n",
    "true_test_labels4 = true_test_labels4.T\n",
    "\n",
    "print(true_test_labels1.shape)\n",
    "print(true_test_labels2.shape)\n",
    "print(true_test_labels3.shape)\n",
    "print(true_test_labels4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 32549)\n",
      "(165, 32549)\n",
      "(165, 32549)\n",
      "(165, 32549)\n",
      "(165, 2000)\n",
      "(165, 2000)\n",
      "(165, 2000)\n",
      "(165, 2000)\n"
     ]
    }
   ],
   "source": [
    "pred_train1 = pred_train1.T\n",
    "pred_train2 = pred_train2.T\n",
    "pred_train3 = pred_train3.T\n",
    "pred_train4 = pred_train4.T\n",
    "\n",
    "print(pred_train1.shape)\n",
    "print(pred_train2.shape)\n",
    "print(pred_train3.shape)\n",
    "print(pred_train4.shape)\n",
    "\n",
    "\n",
    "pred_test1 = pred_test1.T\n",
    "pred_test2 = pred_test2.T\n",
    "pred_test3 = pred_test3.T\n",
    "pred_test4 = pred_test4.T\n",
    "\n",
    "print(pred_test1.shape)\n",
    "print(pred_test2.shape)\n",
    "print(pred_test3.shape)\n",
    "print(pred_test4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "adrs = list(true_train1.columns)\n",
    "trueLabelsTrain = [true_train_labels1, true_train_labels2, true_train_labels3, true_train_labels4]\n",
    "trueLabelsTest = [true_test_labels1, true_test_labels2, true_test_labels3, true_test_labels4]\n",
    "predTrain = [pred_train1, pred_train2, pred_train3, pred_train4]\n",
    "predTest = [pred_test1, pred_test2, pred_test3, pred_test4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllthresholds(pred):\n",
    "    thresholds = {}\n",
    "    index=0\n",
    "    for adr in adrs:\n",
    "        thresholds[adr] = np.linspace(min(pred[index]),max(pred[index]),100)\n",
    "        index+=1\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing best thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestThresholds(true_labels, pred, thresholds):\n",
    "    selectedThreshF1 = []\n",
    "\n",
    "    for adr in range(165):\n",
    "        maxThreshF1 = 0\n",
    "        maxScoreF1 = 0\n",
    "\n",
    "        for threshold in thresholds[adrs[adr]]:\n",
    "            temp = []\n",
    "            #Using training data only\n",
    "            for sample in range(len(pred[adr])):\n",
    "                if pred[adr][sample] > threshold:\n",
    "                    temp.append(1)\n",
    "                else:\n",
    "                    temp.append(0)\n",
    "\n",
    "            scoreF1 = f1_score(true_labels[adr], temp, average= \"macro\")\n",
    "\n",
    "            if scoreF1 > maxScoreF1:\n",
    "                maxThreshF1 = threshold\n",
    "                maxScoreF1 = scoreF1\n",
    "\n",
    "        selectedThreshF1.append(maxThreshF1)   \n",
    "    return selectedThreshF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selectedThresholds = []\n",
    "for i in range(4):\n",
    "    thresholds = getAllthresholds(predTrain[i])\n",
    "    selectedThresholds.append(getBestThresholds(trueLabelsTrain[i], predTrain[i], thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n",
      "165\n",
      "165\n",
      "165\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(len(selectedThresholds[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying thresholds to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(4):\n",
    "    score = {'scoreF1': [], 'scoreAcc': [], 'scoreRoc': []}\n",
    "    pred_test = predTest[i]\n",
    "    thresholds = selectedThresholds[i]\n",
    "    truelabels = trueLabelsTest[i]\n",
    "    for adr in range(165):\n",
    "        temp = []\n",
    "        for sample in range(2000):\n",
    "            if pred_test[adr][sample] > thresholds[adr]:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        \n",
    "        score['scoreF1'].append(f1_score(truelabels[adr], temp, average= \"macro\"))\n",
    "        score['scoreAcc'].append(accuracy_score(truelabels[adr], temp))\n",
    "        score['scoreRoc'].append(roc_auc_score(truelabels[adr], temp, average= \"macro\"))\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame.from_dict(scores[0])\n",
    "df2 = pd.DataFrame.from_dict(scores[1])\n",
    "df3 = pd.DataFrame.from_dict(scores[2])\n",
    "df4 = pd.DataFrame.from_dict(scores[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = df1.columns)\n",
    "df[\"ADR\"] = adrs\n",
    "for i in range(165):\n",
    "    for j in range(3):\n",
    "        df.iloc[i,j] = (df1.iloc[i,j]+df2.iloc[i,j]+df3.iloc[i,j]+df4.iloc[i,j])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scoreF1</th>\n",
       "      <th>scoreAcc</th>\n",
       "      <th>scoreRoc</th>\n",
       "      <th>ADR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.703603</td>\n",
       "      <td>0.823625</td>\n",
       "      <td>0.714643</td>\n",
       "      <td>bruxism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.698954</td>\n",
       "      <td>0.8155</td>\n",
       "      <td>0.707722</td>\n",
       "      <td>Mod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.697901</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>0.69651</td>\n",
       "      <td>Drug.addiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.692844</td>\n",
       "      <td>0.861875</td>\n",
       "      <td>0.693553</td>\n",
       "      <td>fibromyalgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.687047</td>\n",
       "      <td>0.777375</td>\n",
       "      <td>0.693516</td>\n",
       "      <td>arteriosclerotic.heart.disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.577485</td>\n",
       "      <td>0.70125</td>\n",
       "      <td>0.579084</td>\n",
       "      <td>eruption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.576908</td>\n",
       "      <td>0.736625</td>\n",
       "      <td>0.578682</td>\n",
       "      <td>Aspartate.Aminotransferase.Increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.574879</td>\n",
       "      <td>0.730875</td>\n",
       "      <td>0.575932</td>\n",
       "      <td>allergic.dermatitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.570972</td>\n",
       "      <td>0.662875</td>\n",
       "      <td>0.570856</td>\n",
       "      <td>edema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.566481</td>\n",
       "      <td>0.696375</td>\n",
       "      <td>0.567218</td>\n",
       "      <td>Feeling.unwell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      scoreF1  scoreAcc  scoreRoc                                  ADR\n",
       "100  0.703603  0.823625  0.714643                              bruxism\n",
       "91   0.698954    0.8155  0.707722                                  Mod\n",
       "152  0.697901    0.8615   0.69651                       Drug.addiction\n",
       "158  0.692844  0.861875  0.693553                         fibromyalgia\n",
       "51   0.687047  0.777375  0.693516       arteriosclerotic.heart.disease\n",
       "..        ...       ...       ...                                  ...\n",
       "49   0.577485   0.70125  0.579084                             eruption\n",
       "87   0.576908  0.736625  0.578682  Aspartate.Aminotransferase.Increase\n",
       "84   0.574879  0.730875  0.575932                  allergic.dermatitis\n",
       "31   0.570972  0.662875  0.570856                                edema\n",
       "59   0.566481  0.696375  0.567218                       Feeling.unwell\n",
       "\n",
       "[165 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['scoreF1'], ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"average-thirty-f1-based.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data - 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty = pd.read_excel(\"fifty_percent.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Actual Training Data\n",
    "true_train1 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_1.csv\")\n",
    "true_train2 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_2.csv\")\n",
    "true_train3 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_3.csv\")\n",
    "true_train4 = pd.read_csv(\"prediction_of_ADR/ADR_dataset_for_training_subset_4.csv\")\n",
    "\n",
    "#Reading Predictions\n",
    "pred_train1 = np.load(\"pre1-f-train.npy\")\n",
    "pred_train2 = np.load(\"pre2-f-train.npy\")\n",
    "pred_train3 = np.load(\"pre3-f-train.npy\")\n",
    "pred_train4 = np.load(\"pre4-f-train.npy\")\n",
    "\n",
    "true_train1.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_train2.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_train3.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_train4.drop(\"Unnamed: 0\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Actual Testing Data\n",
    "true_test1 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_1.csv\")\n",
    "true_test2 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_2.csv\")\n",
    "true_test3 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_3.csv\")\n",
    "true_test4 = pd.read_csv(\"prediction_of_ADR/ADR_validation_for_validation_subset_4.csv\")\n",
    "\n",
    "#Reading Predictions\n",
    "pred_test1 = np.load(\"pre1-f.npy\")\n",
    "pred_test2 = np.load(\"pre2-f.npy\")\n",
    "pred_test3 = np.load(\"pre3-f.npy\")\n",
    "pred_test4 = np.load(\"pre4-f.npy\")\n",
    "\n",
    "true_test1.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_test2.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_test3.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "true_test4.drop(\"Unnamed: 0\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_train1 = true_train1[thirty['ADR']]\n",
    "true_train2 = true_train2[thirty['ADR']]\n",
    "true_train3 = true_train3[thirty['ADR']]\n",
    "true_train4 = true_train4[thirty['ADR']]\n",
    "\n",
    "true_test1 = true_test1[thirty['ADR']]\n",
    "true_test2 = true_test2[thirty['ADR']]\n",
    "true_test3 = true_test3[thirty['ADR']]\n",
    "true_test4 = true_test4[thirty['ADR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 32549)\n",
      "(68, 32549)\n",
      "(68, 32549)\n",
      "(68, 32549)\n",
      "(68, 2000)\n",
      "(68, 2000)\n",
      "(68, 2000)\n",
      "(68, 2000)\n"
     ]
    }
   ],
   "source": [
    "true_train_labels1 = true_train1.values\n",
    "true_train_labels2 = true_train2.values\n",
    "true_train_labels3 = true_train3.values\n",
    "true_train_labels4 = true_train4.values\n",
    "\n",
    "true_train_labels1 = true_train_labels1.T\n",
    "true_train_labels2 = true_train_labels2.T\n",
    "true_train_labels3 = true_train_labels3.T\n",
    "true_train_labels4 = true_train_labels4.T\n",
    "\n",
    "print(true_train_labels1.shape)\n",
    "print(true_train_labels2.shape)\n",
    "print(true_train_labels3.shape)\n",
    "print(true_train_labels4.shape)\n",
    "\n",
    "\n",
    "true_test_labels1 = true_test1.values\n",
    "true_test_labels2 = true_test2.values\n",
    "true_test_labels3 = true_test3.values\n",
    "true_test_labels4 = true_test4.values\n",
    "\n",
    "true_test_labels1 = true_test_labels1.T\n",
    "true_test_labels2 = true_test_labels2.T\n",
    "true_test_labels3 = true_test_labels3.T\n",
    "true_test_labels4 = true_test_labels4.T\n",
    "\n",
    "print(true_test_labels1.shape)\n",
    "print(true_test_labels2.shape)\n",
    "print(true_test_labels3.shape)\n",
    "print(true_test_labels4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 32549)\n",
      "(68, 32549)\n",
      "(68, 32549)\n",
      "(68, 32549)\n",
      "(68, 2000)\n",
      "(68, 2000)\n",
      "(68, 2000)\n",
      "(68, 2000)\n"
     ]
    }
   ],
   "source": [
    "pred_train1 = pred_train1.T\n",
    "pred_train2 = pred_train2.T\n",
    "pred_train3 = pred_train3.T\n",
    "pred_train4 = pred_train4.T\n",
    "\n",
    "print(pred_train1.shape)\n",
    "print(pred_train2.shape)\n",
    "print(pred_train3.shape)\n",
    "print(pred_train4.shape)\n",
    "\n",
    "\n",
    "pred_test1 = pred_test1.T\n",
    "pred_test2 = pred_test2.T\n",
    "pred_test3 = pred_test3.T\n",
    "pred_test4 = pred_test4.T\n",
    "\n",
    "print(pred_test1.shape)\n",
    "print(pred_test2.shape)\n",
    "print(pred_test3.shape)\n",
    "print(pred_test4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "adrs = list(true_train1.columns)\n",
    "trueLabelsTrain = [true_train_labels1, true_train_labels2, true_train_labels3, true_train_labels4]\n",
    "trueLabelsTest = [true_test_labels1, true_test_labels2, true_test_labels3, true_test_labels4]\n",
    "predTrain = [pred_train1, pred_train2, pred_train3, pred_train4]\n",
    "predTest = [pred_test1, pred_test2, pred_test3, pred_test4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllthresholds(pred):\n",
    "    thresholds = {}\n",
    "    index=0\n",
    "    for adr in adrs:\n",
    "        thresholds[adr] = np.linspace(min(pred[index]),max(pred[index]),100)\n",
    "        index+=1\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing best thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestThresholds(true_labels, pred, thresholds):\n",
    "    selectedThreshF1 = []\n",
    "\n",
    "    for adr in range(68):\n",
    "        maxThreshF1 = 0\n",
    "        maxScoreF1 = 0\n",
    "\n",
    "        for threshold in thresholds[adrs[adr]]:\n",
    "            temp = []\n",
    "            #Using training data only\n",
    "            for sample in range(len(pred[adr])):\n",
    "                if pred[adr][sample] > threshold:\n",
    "                    temp.append(1)\n",
    "                else:\n",
    "                    temp.append(0)\n",
    "\n",
    "            scoreF1 = f1_score(true_labels[adr], temp, average= \"macro\")\n",
    "\n",
    "            if scoreF1 > maxScoreF1:\n",
    "                maxThreshF1 = threshold\n",
    "                maxScoreF1 = scoreF1\n",
    "\n",
    "        selectedThreshF1.append(maxThreshF1)   \n",
    "    return selectedThreshF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedThresholds = []\n",
    "for i in range(4):\n",
    "    thresholds = getAllthresholds(predTrain[i])\n",
    "    selectedThresholds.append(getBestThresholds(trueLabelsTrain[i], predTrain[i], thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "68\n",
      "68\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(len(selectedThresholds[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding thresholds to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(4):\n",
    "    score = {'scoreF1': [], 'scoreAcc': [], 'scoreRoc': []}\n",
    "    pred_test = predTest[i]\n",
    "    thresholds = selectedThresholds[i]\n",
    "    truelabels = trueLabelsTest[i]\n",
    "    for adr in range(68):\n",
    "        temp = []\n",
    "        for sample in range(2000):\n",
    "            if pred_test[adr][sample] > thresholds[adr]:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        \n",
    "        score['scoreF1'].append(f1_score(truelabels[adr], temp, average= \"macro\"))\n",
    "        score['scoreAcc'].append(accuracy_score(truelabels[adr], temp))\n",
    "        score['scoreRoc'].append(roc_auc_score(truelabels[adr], temp, average= \"macro\"))\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame.from_dict(scores[0])\n",
    "df2 = pd.DataFrame.from_dict(scores[1])\n",
    "df3 = pd.DataFrame.from_dict(scores[2])\n",
    "df4 = pd.DataFrame.from_dict(scores[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = df1.columns)\n",
    "df[\"ADR\"] = adrs\n",
    "for i in range(68):\n",
    "    for j in range(3):\n",
    "        df.iloc[i,j] = (df1.iloc[i,j]+df2.iloc[i,j]+df3.iloc[i,j]+df4.iloc[i,j])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scoreF1</th>\n",
       "      <th>scoreAcc</th>\n",
       "      <th>scoreRoc</th>\n",
       "      <th>ADR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.689025</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.693298</td>\n",
       "      <td>arteriosclerotic.heart.disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.683016</td>\n",
       "      <td>0.774375</td>\n",
       "      <td>0.683029</td>\n",
       "      <td>elevated.cholesterol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.682733</td>\n",
       "      <td>0.777875</td>\n",
       "      <td>0.681822</td>\n",
       "      <td>acid.reflux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.674281</td>\n",
       "      <td>0.744875</td>\n",
       "      <td>0.68017</td>\n",
       "      <td>apoplexy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.672434</td>\n",
       "      <td>0.74375</td>\n",
       "      <td>0.67101</td>\n",
       "      <td>Aching.joints</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.593388</td>\n",
       "      <td>0.689125</td>\n",
       "      <td>0.592499</td>\n",
       "      <td>heart.rate.increased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.583592</td>\n",
       "      <td>0.71675</td>\n",
       "      <td>0.582457</td>\n",
       "      <td>loss.of.consciousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.582767</td>\n",
       "      <td>0.69825</td>\n",
       "      <td>0.586751</td>\n",
       "      <td>eruption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.570326</td>\n",
       "      <td>0.658875</td>\n",
       "      <td>0.570694</td>\n",
       "      <td>edema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.570108</td>\n",
       "      <td>0.702125</td>\n",
       "      <td>0.569562</td>\n",
       "      <td>Feeling.unwell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     scoreF1  scoreAcc  scoreRoc                             ADR\n",
       "51  0.689025     0.781  0.693298  arteriosclerotic.heart.disease\n",
       "45  0.683016  0.774375  0.683029            elevated.cholesterol\n",
       "47  0.682733  0.777875  0.681822                     acid.reflux\n",
       "38  0.674281  0.744875   0.68017                        apoplexy\n",
       "25  0.672434   0.74375   0.67101                   Aching.joints\n",
       "..       ...       ...       ...                             ...\n",
       "39  0.593388  0.689125  0.592499            heart.rate.increased\n",
       "60  0.583592   0.71675  0.582457           loss.of.consciousness\n",
       "49  0.582767   0.69825  0.586751                        eruption\n",
       "31  0.570326  0.658875  0.570694                           edema\n",
       "59  0.570108  0.702125  0.569562                  Feeling.unwell\n",
       "\n",
       "[68 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['scoreF1'], ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"average-fifty-f1-based.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
